# cage-challenge-4

This repository contains three independent reinforcement learning implementations: **IPPO**, **MAPPO**, and **HMARL**. Each directory includes its own training script and can be run independently.

---

## ğŸ“ Project Structure

```
cage-challenge-4/
â”‚
â”œâ”€â”€ Ippo/
â”‚   â””â”€â”€ ippo_hyperparameter.py
â”‚
â”œâ”€â”€ Mappo/
â”‚   â””â”€â”€ mappo_hyperparameter.py
â”‚
â””â”€â”€ Hmarl/
    â””â”€â”€ train_subpolicies.py
```

---

## âœ… Setup & Requirements

Itâ€™s recommended to use a **virtual environment** to manage dependencies.

### 1ï¸âƒ£ Create and activate a virtual environment

**On macOS/Linux:**

```bash
python3 -m venv venv
source venv/bin/activate
```

**On Windows:**

```bash
python -m venv venv
venv\Scripts\activate
```

### 2ï¸âƒ£ Install requirements

Make sure you have a `requirements.txt` file in the project root.  
Install all dependencies with:

```bash
pip install -r requirements.txt
```


## ğŸš€ How to Run

### âš¡ IPPO

Navigate into the `Ippo` directory and run:

```bash
python ippo_hyperparameter.py [options]
```

**Available arguments for IPPO:**

| Argument | Description | Example |
| -------- | ----------- | ------- |
| `--cluster` | Run under SLURM (submit job via `sbatch`). | `--cluster` |
| `--no-optuna` | Disable Optuna hyperparameter tuning and use fixed hyperparameters. | `--no-optuna` |
| `--lr` | Learning rate (float). | `--lr 5e-5` |
| `--clip-param` | PPO clipping ratio. | `--clip-param 0.2` |
| `--train-batch-size` | Total training batch size. | `--train-batch-size 150000` |
| `--minibatch-size` | Minibatch size. | `--minibatch-size 4096` |

**Example:**

```bash
cd Ippo
python ippo_hyperparameter.py --no-optuna --lr 5e-5 --clip-param 0.2 --train-batch-size 150000 --minibatch-size 4096
```

---

### âš¡ MAPPO

Navigate into the `Mappo` directory and run:

```bash
cd Mappo
python mappo_hyperparameter.py
```

_No additional arguments are required for MAPPO._

---

### âš¡ HMARL

Navigate into the `Hmarl` directory and run:

```bash
cd Hmarl
python train_subpolicies.py
```

_No additional arguments are required for HMARL._

---

## âœ… Requirements

Make sure to install the required Python packages.  
You can create a `requirements.txt` and install with:

```bash
pip install -r requirements.txt
```

---

## ğŸ“Œ Notes

- The `--cluster` flag is useful if running on a compute cluster with SLURM.
- By default, IPPO uses Optuna for hyperparameter tuning. Use `--no-optuna` to disable tuning and use your fixed hyperparameters.

---


